{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "# Data extraction\n",
        "\n",
        ".. admonition:: About data generation\n",
        "\n",
        "    The audio chunks are the output of the software ``noise-extractor`` on the audio files provided by CSC. For a more detailed description of the dataset, see `datasets`.\n",
        "\n",
        "In this notebook, data will be extracted from the raw data files and stored in a csv file. In particular we want to extract the first 13 MFCCs from the audio files provided by the CSC. The MFCCs will be stored in a csv file with the following columns:\n",
        "\n",
        "* `mfcc_1` to `mfcc_13`: the 13 MFCCs\n",
        "* `label`: a number between 0 and 3 that represents all possible combinations of reading and acquisition conditions\n",
        "* `noise_type`: the type of noise present in the audio file\n",
        "\n",
        "The type of noises that are present in the audio files are:\n",
        "\n",
        "* `A`: for noise between -50 and -63 dB\n",
        "* `B`: for noise between -63 and -69 dB\n",
        "* `C`: for noise between -69 and -72 dB (teoretically the limit is -72 dB, but we will take in account also noise below this limit)\n",
        "\n",
        "Firstly, as illustrated in the pipeline of :numref:`pipeline`, we get the list of audio files that are present in the `data` folder. Those files have been generated using the `noise-extractor` tool. The following analysis takes in consideration files generated via:\n",
        "\n",
        "```console\n",
        "noise-extractor -i data/audio_samples -d data/dataset/pretto -l 500\n",
        "noise-extractor -i data/audio_samples -d data/dataset/berio_nono -l 500\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then the files are collected in two lists:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "def collect_audio_files(path):\n",
        "    return [\n",
        "        os.path.join(dp, f) for dp, dn, filenames in os.walk(path)\n",
        "        for f in filenames if f.endswith('.wav')\n",
        "    ]\n",
        "\n",
        "\n",
        "audio_pretto_list = collect_audio_files(\"../data/dataset/pretto\")\n",
        "audio_berio_list = collect_audio_files(\"../data/dataset/berio_nono\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The audio files are then loaded and the MFCCs are extracted. Then all audio features are collected in a list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import json\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "with open('../src/ml/datasets/data/config.json') as f:\n",
        "    test_labels = json.load(f)['targets']['test']['labels']\n",
        "\n",
        "\n",
        "def extract_mfcc(filepath: str) -> list[float]:\n",
        "    \"\"\"Get the mean of the first 13 mfccs of a given audio file.\"\"\"\n",
        "    audio, sr = librosa.load(filepath, sr=96000)\n",
        "    mfccs = librosa.feature.mfcc(audio, sr=sr, n_mfcc=13)\n",
        "    mean_mfccs = []\n",
        "    for e in mfccs:\n",
        "        mean_mfccs.append(np.mean(e))\n",
        "    return mean_mfccs\n",
        "\n",
        "\n",
        "def collect_features(audio_list: list[str], dset: str = 'berio'):\n",
        "    \"\"\"Collects the features of all audio files in the given list.\"\"\"\n",
        "    labels = []\n",
        "    noise_type = []\n",
        "    mfccs = []\n",
        "    for audiofile in audio_list:\n",
        "        # extract mfccs\n",
        "        mfccs.append(extract_mfcc(audiofile))\n",
        "\n",
        "        # extract labels\n",
        "        folder_name = audiofile.split('/')[4]\n",
        "        if dset == 'pretto':\n",
        "            folder_name = folder_name.split('_')\n",
        "            write = folder_name[0][1::]\n",
        "            read = folder_name[1][1::]\n",
        "\n",
        "        elif dset == 'berio':\n",
        "            write = read = test_labels[folder_name]\n",
        "        labels.append(f'{write}_{read}')\n",
        "\n",
        "        # extract silence type\n",
        "        noise_type.append(os.path.basename(audiofile).split('_')[0])\n",
        "    return labels, mfccs, noise_type\n",
        "\n",
        "\n",
        "pretto_features = collect_features(audio_pretto_list, \"pretto\")\n",
        "berio_features = collect_features(audio_berio_list, \"berio\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The features are then stored in a csv file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def create_dataframe(features, name):\n",
        "    labels, mfccs, noise_type = features\n",
        "    data = []\n",
        "    for label, noise_type, mfccs in zip(labels, noise_type, mfccs):\n",
        "        data.append([label, noise_type, *mfccs])\n",
        "\n",
        "    headers = [\n",
        "        'label', 'noise_type', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5',\n",
        "        'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12',\n",
        "        'mfcc13'\n",
        "    ]\n",
        "    dataframe = pd.DataFrame(data, columns=headers)\n",
        "    dataframe.to_csv(f'../data/{name}', index=False)\n",
        "\n",
        "\n",
        "create_dataframe(pretto_features, 'pretto.csv')\n",
        "create_dataframe(berio_features, 'berio.csv')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "audiohandler-BO7RUw7L-py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b599be24a8d93884fd001ad20dc2e37bac390bcb7f16df6697b044b0aa8ad4fa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
